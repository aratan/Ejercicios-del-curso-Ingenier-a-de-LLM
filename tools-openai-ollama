import os
import json
from openai import OpenAI
import gradio as gr

# Inicializar el cliente de OpenAI
MODEL = 'qwen2.5'
openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')

# Mensaje del sistema que proporciona el contexto al modelo
system_message = (
    "Eres un asistente útil para una aerolínea llamada FlightAI. "
    "Proporciona respuestas breves y corteses, de no más de una oración. "
    "Sé siempre preciso. Si no sabes la respuesta, dilo."
)

# Precios de los billetes según la ciudad
ticket_prices = {"london": "$799", "paris": "$899", "tokyo": "$1400", "berlin": "$499"}

# Función para obtener el precio de un billete
def get_ticket_price(destination_city):
    print(f"Tool get_ticket_price called for {destination_city}")
    return ticket_prices.get(destination_city.lower(), "Unknown")

# Definición de la función de reserva
book_function = {
    "type": "function",
    "function": {
        "name": "book_ticket",
        "description": "Confirma la reserva de un billete a la ciudad de destino.",
        "parameters": {
            "type": "object",
            "properties": {
                "destination_city": {
                    "type": "string",
                    "description": "La ciudad a la que el cliente quiere reservar el billete.",
                },
            },
            "required": ["destination_city"],
        },
    }
}

# Definición de la función de consulta de precios
price_function = {
    "type": "function",
    "function": {
        "name": "get_ticket_price",
        "description": "Obtener el precio de un billete de ida y vuelta a la ciudad de destino.",
        "parameters": {
            "type": "object",
            "properties": {
                "destination_city": {
                    "type": "string",
                    "description": "La ciudad a la que el cliente quiere viajar.",
                },
            },
            "required": ["destination_city"],
        },
    }
}

# Lista de herramientas disponibles
tools = [price_function, book_function]

# Función principal del chat que maneja las interacciones
def chat(message, history):
    # Construcción del historial de mensajes
    messages = [{"role": "system", "content": system_message}]
    messages.extend(
        {"role": role, "content": content}
        for pair in history
        for role, content in [("user", pair[0]), ("assistant", pair[1])]
    )
    messages.append({"role": "user", "content": message})

    # Genera la respuesta del modelo
    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools, tool_choice="auto")

    # Procesa las llamadas a herramientas si las hay
    if response.choices[0].finish_reason == "tool_calls":
        tool_calls = response.choices[0].message.tool_calls
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)

            if function_name == "get_ticket_price":
                city = arguments.get('destination_city')
                tool_response = get_ticket_price(city)
            elif function_name == "book_ticket":
                city = arguments.get('destination_city')
                tool_response = f"El billete a {city} ha sido reservado. Gracias."
            else:
                tool_response = f"No se reconoce la función: {function_name}"

            messages.append(response.choices[0].message)
            messages.append({
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": function_name,
                "content": tool_response,
            })

        # Nueva interacción con el modelo tras procesar las herramientas
        response = openai.chat.completions.create(model=MODEL, messages=messages)

    return response.choices[0].message.content

# Interfaz de Gradio para el chat
gr.ChatInterface(fn=chat).launch()
